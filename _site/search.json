[
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take Home Exercise 3",
    "section": "",
    "text": "Using the data provide by the VAST challenge, we are looking into the Mini-Challenge 3 (MC3) to identify compaines possibly engaged in illegal, unreported, and unregulated (IUU) fishing."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#load-packages",
    "title": "Take Home Exercise 3",
    "section": "Load Packages",
    "text": "Load Packages\n\n\nShow the code\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, graphlayouts, ggforce,skimr,tidytext, tidyverse,igraph, topicmodels,tm)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-import",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-import",
    "title": "Take Home Exercise 3",
    "section": "Data Import",
    "text": "Data Import\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC3.json into R environment.\n\n\nShow the code\nmc3_data &lt;- fromJSON(\"data/MC3.json\")\n\n\nExamine the data, this is not a directed graph, not looking into in- and out-degree of the nodes."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-edges",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-edges",
    "title": "Take Home Exercise 3",
    "section": "Extracting edges",
    "text": "Extracting edges\nBelow code chunk changes the links field into character field.\n\n\nShow the code\nmc3_edges &lt;- as_tibble(mc3_data$links)%&gt;%\n  distinct() %&gt;%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %&gt;%\n  group_by(source, target, type) %&gt;%\n    summarise(weights = n()) %&gt;%\n  filter(source!=target)%&gt;%\n  ungroup"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-nodes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-nodes",
    "title": "Take Home Exercise 3",
    "section": "Extracting nodes",
    "text": "Extracting nodes\n\n\nShow the code\nmc3_nodes &lt;- as_tibble(mc3_data$nodes) %&gt;%\n#  distinct()%&gt;%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %&gt;%\n    select(id, country, type, revenue_omu, product_services)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploring-the-edges-dataframe",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploring-the-edges-dataframe",
    "title": "Take Home Exercise 3",
    "section": "Exploring the edges dataframe",
    "text": "Exploring the edges dataframe\nIn the code chunk below, skim() of skimr package is used to display the summary statistics of mc3_edges tibble data frame.\n\n\nShow the code\nskim(mc3_edges)\n\n\n\nData summary\n\n\nName\nmc3_edges\n\n\nNumber of rows\n24036\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsource\n0\n1\n6\n700\n0\n12856\n0\n\n\ntarget\n0\n1\n6\n28\n0\n21265\n0\n\n\ntype\n0\n1\n16\n16\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nweights\n0\n1\n1\n0\n1\n1\n1\n1\n1\n▁▁▇▁▁\n\n\n\n\n\nThe report above reveals that there is not missing values in all fields.\nIn the code chunk below, datatable() of DT package is used to display mc3_edges tibble data frame as an interactive table on the html document.\n\n\nShow the code\nDT::datatable(mc3_edges)\n\n\n\n\n\n\n\nBelow code chunks, counting number of companies a person owns and the number of owners a company has.\n\n\nShow the code\nggplot(data = mc3_edges,\n       aes(x=type)) +\n  geom_bar()\n\n\n\n\n\nShow the code\nunique_ids &lt;- unique(mc3_edges$target)\nnum_unique_ids &lt;- length(unique_ids)\nnum_unique_ids\n\n\n[1] 21265\n\n\nShow the code\nNoofcompanies &lt;- mc3_edges %&gt;%\n  group_by(target, source, type) %&gt;%\n  filter(type == \"Beneficial Owner\") %&gt;%\n  summarise(count=n()) %&gt;%\n  group_by(target)%&gt;%\n  summarise(count=sum(count))\n\npsych::describe(Noofcompanies)\n\n\n        vars     n   mean      sd median trimmed     mad min   max range skew\ntarget*    1 15305 7653.0 4418.32   7653    7653 5672.43   1 15305 15304 0.00\ncount      2 15305    1.1    0.40      1       1    0.00   1     9     8 6.28\n        kurtosis    se\ntarget*    -1.20 35.71\ncount      61.69  0.00\n\n\n\n\nShow the code\nNoofowners &lt;- mc3_edges %&gt;%\n  group_by(source, target, type) %&gt;%\n  summarise(count=n()) %&gt;%\n  group_by(source)%&gt;%\n  summarise(count=sum(count))\n\npsych::describe(Noofowners)\n\n\n        vars     n    mean      sd median trimmed     mad min   max range  skew\nsource*    1 12856 6428.50 3711.35 6428.5 6428.50 4765.08   1 12856 12855  0.00\ncount      2 12856    1.87    3.47    1.0    1.22    0.00   1   120   119 11.36\n        kurtosis    se\nsource*    -1.20 32.73\ncount     215.82  0.03\n\n\nBelow code chunk we are interested to see top 50 owners owning multiple companies, with John Smith and Michael Johnson have the highest of 9 companies to their name. This could be suspicious as why they need so many companies.\n\n\nShow the code\nlist_top_50 &lt;- Noofcompanies %&gt;%\n  arrange(desc(count)) %&gt;%\n  top_n(50, wt = count) \n\nggplot(data = list_top_50, \n       aes(x = reorder(target, -count), y = count)) +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploring-the-nodes-dataframe",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploring-the-nodes-dataframe",
    "title": "Take Home Exercise 3",
    "section": "Exploring the nodes dataframe",
    "text": "Exploring the nodes dataframe\n\n\nShow the code\nskim(mc3_nodes)\n\n\n\nData summary\n\n\nName\nmc3_nodes\n\n\nNumber of rows\n27622\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nid\n0\n1\n6\n64\n0\n22929\n0\n\n\ncountry\n0\n1\n2\n15\n0\n100\n0\n\n\ntype\n0\n1\n7\n16\n0\n3\n0\n\n\nproduct_services\n0\n1\n4\n1737\n0\n3244\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrevenue_omu\n21515\n0.22\n1822155\n18184433\n3652.23\n7676.36\n16210.68\n48327.66\n310612303\n▇▁▁▁▁\n\n\n\n\n\nThe report above reveals that there is no missing values in all fields.\nIn the code chunk below, datatable() of DT package is used to display mc3_nodes tibble data frame as an interactive table on the html document.\n\n\nShow the code\nDT::datatable(mc3_nodes)\n\n\n\n\n\n\n\nBelow code chunk to find out how is the distribution among the types of ownerhships.\n\n\nShow the code\nggplot(data = mc3_nodes,\n       aes(x = type)) +\n  geom_bar()\n\n\n\n\n\nBelow code chunk we check on the revenue distribution among the types of ownerships.\n\n\nShow the code\nggplot(data = mc3_nodes,\n       aes(x= type,\n         y = revenue_omu)) +\n  geom_boxplot()\n\n\n\n\n\nWe combined the nodes and edges data so we can find out more on the owner-company relationships.\n\n\nShow the code\ncombined &lt;- left_join(mc3_nodes,mc3_edges,\n                  by=c(\"id\"=\"source\"))\n\n\nBelow code chunk to find out more on which owners have high number of companies also generating a lot of revenue.\n\n\nShow the code\ncombined &lt;- combined %&gt;%\n  group_by(target, type.y, id, country, type.x, product_services)%&gt;%\n  summarize(revenue_omu) %&gt;%\n  filter(type.y == \"Beneficial Owner\")\n\nfiltered_combined &lt;- combined %&gt;%\n  filter(target %in% list_top_50$target)%&gt;%\n  arrange(desc(revenue_omu))\n\nggplot(data = filtered_combined, \n       aes(x = target, y = revenue_omu)) +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) \n\n\n\n\n\nMichael Johnson, Mark Miller and James Rodriguez stand out from the above chart, below code we want to see what business they did that generate more revenue.\n\n\nShow the code\nTop_3_Revenue&lt;- combined %&gt;%\n  filter (target %in% c(\"Michael Johnson\", \"Mark Miller\",\"James Rodriguez\")) %&gt;%\n  arrange(desc(revenue_omu))\n\nDT::datatable(Top_3_Revenue)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#insights",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#insights",
    "title": "Take Home Exercise 3",
    "section": "Insights",
    "text": "Insights\nFrom the above data table, we see that Michael Johnson is involved in the fishing business and having many companies in different countries. The FishEye could probably look more into his business landscape across different companies and his business activities to understand more."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#simple-word-count",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#simple-word-count",
    "title": "Take Home Exercise 3",
    "section": "Simple word count",
    "text": "Simple word count\nThe code chunk below calculates number of times the word fish appeared in the field product_services.\n\n\nShow the code\nmc3_nodes %&gt;% \n    mutate(n_fish = str_count(product_services, \"fish\")) \n\n\n# A tibble: 27,622 × 6\n   id                          country type  revenue_omu product_services n_fish\n   &lt;chr&gt;                       &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;             &lt;int&gt;\n 1 Jones LLC                   ZH      Comp…  310612303. Automobiles           0\n 2 Coleman, Hall and Lopez     ZH      Comp…  162734684. Passenger cars,…      0\n 3 Aqua Advancements Sashimi … Oceanus Comp…  115004667. Holding firm wh…      0\n 4 Makumba Ltd. Liability Co   Utopor… Comp…   90986413. Car service, ca…      0\n 5 Taylor, Taylor and Farrell  ZH      Comp…   81466667. Fully electric …      0\n 6 Harmon, Edwards and Bates   ZH      Comp…   75070435. Discount superm…      0\n 7 Punjab s Marine conservati… Riodel… Comp…   72167572. Beef, pork, chi…      0\n 8 Assam   Limited Liability … Utopor… Comp…   72162317. Power and Gas s…      0\n 9 Ianira Starfish Sagl Import Rio Is… Comp…   68832979. Light commercia…      0\n10 Moran, Lewis and Jimenez    ZH      Comp…   65592906. Automobiles, tr…      0\n# ℹ 27,612 more rows"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#tokenisation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#tokenisation",
    "title": "Take Home Exercise 3",
    "section": "Tokenisation",
    "text": "Tokenisation\nThe word tokenisation have different meaning in different scientific domains. In text sensing, tokenisation is the process of breaking up a given text into units called tokens. Tokens can be individual words, phrases or even whole sentences. In the process of tokenisation, some characters like punctuation marks may be discarded. The tokens usually become the input for the processes like parsing and text mining.\nIn the code chunk below, unnest_token() of tidytext is used to split text in product_services field into words.\n\n\nShow the code\ntoken_nodes &lt;- mc3_nodes %&gt;%\n  unnest_tokens(word, \n                product_services)\n\n\nThe two basic arguments to unnest_tokens() used here are column names. First we have the output column name that will be created as the text is unnested into it (word, in this case), and then the input column that the text comes from (product_services, in this case).\n\n\nShow the code\ntoken_nodes %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  top_n(15) %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")\n\n\n\n\n\nThe bar chart reveals that the unique words contains some words that may not be useful to use. For instance “a” and “to”. In the word of text mining we call those words stop words. You want to remove these words from your analysis as they are fillers used to compose a sentence.\nUsing filter we also discover many “character(0)” which has no meaning in itself, we will also proceed to replace them with “NA”."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#removing-stopwords",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#removing-stopwords",
    "title": "Take Home Exercise 3",
    "section": "Removing stopwords",
    "text": "Removing stopwords\n\n\nShow the code\ntoken_nodes$word[token_nodes$word == \"character\"] &lt;- \"NA\"\ntoken_nodes$word[token_nodes$word == \"0\"] &lt;- \"NA\"\n\n\n\n\nShow the code\nstopwords_removed &lt;- token_nodes %&gt;% \n  anti_join(stop_words)\n\n\n\n\nShow the code\nstopwords_removed %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  top_n(15) %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")\n\n\n\n\n\n\n\nShow the code\nstopwords_removed %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  top_n(20) %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  filter(!word %in% head(word, 3)) %&gt;%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n  labs(x = \"Count\",\n       y = \"Unique words\",\n       title = \"Count of unique words found in product_services field\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#building-network-model-with-tidygraph",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#building-network-model-with-tidygraph",
    "title": "Take Home Exercise 3",
    "section": "Building network model with tidygraph",
    "text": "Building network model with tidygraph\nFrom the above text insights, we are interested to see the network of companies of Beneficial Owners with fish as their product services.\n\n\nShow the code\nmc3_nodes_fish &lt;- stopwords_removed %&gt;%\n  filter(stopwords_removed$word == \"fish\")\n\n\n\n\nShow the code\nmc3_edges_fish &lt;- mc3_edges[mc3_edges$source %in% mc3_nodes_fish$id,] %&gt;%\n  filter(type == \"Beneficial Owner\")\n\nid1 &lt;- mc3_edges_fish %&gt;%\n  select(source) %&gt;%\n  rename(id = source) \nid2 &lt;- mc3_edges_fish %&gt;% \n  select(target) %&gt;% \n  rename(id = target) \nmc3_nodes_fish &lt;- rbind(id1, id2) %&gt;%\n  distinct() %&gt;% \n  left_join(mc3_nodes_fish,\n            unmatched = \"drop\") \n\n\n\n\nShow the code\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes_fish,                        \n                      edges = mc3_edges_fish,                        \n                        directed = FALSE)  \n\nmc3_graph&lt;-mc3_graph%&gt;%\n  mutate(betweenness=centrality_betweenness())\n\nmc3_graph\n\n\n# A tbl_graph: 1190 nodes and 876 edges\n#\n# An unrooted forest with 314 trees\n#\n# A tibble: 1,190 × 6\n  id                                 country type  revenue_omu word  betweenness\n  &lt;chr&gt;                              &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n1 Adams Group                        ZH      Comp…       9056. fish            0\n2 Albertine Rift  NV Family          Marebak Comp…       9761. fish            3\n3 Allen PLC                          ZH      Comp…      61582. fish            0\n4 Ancla del Mar Pic Worldwide        Thessa… Comp…       4667. fish            3\n5 Andhra Pradesh  OJSC Marine conse… Yggdra… Comp…      25758. fish            0\n6 Andhra Pradesh  OJSC Marine conse… Yggdra… Comp…      25758. fish            0\n# ℹ 1,184 more rows\n#\n# A tibble: 876 × 4\n   from    to type             weights\n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;              &lt;int&gt;\n1     1   321 Beneficial Owner       1\n2     2   322 Beneficial Owner       1\n3     2   323 Beneficial Owner       1\n# ℹ 873 more rows\n\n\nUsing the distribution function to understand the centrality_betweenness().\n\n\nShow the code\nggplot(as.data.frame(mc3_graph),aes(x=betweenness))+\n  geom_histogram(bins=10,fill=\"lightblue\",colour=\"black\")+\n  ggtitle(\"Distribution of centrality betweenness\")+\n  theme(plot.title = element_text(hjust=0.5))\n\n\n\n\n\nLooking at this, we can filter our records where the centrality between is greater than 50 to understand the interactions.\n\n\nShow the code\nset.seed (1234)\ndegrees &lt;- degree(mc3_graph)\nV(mc3_graph)$degree &lt;- degrees\n\nmc3_graph %&gt;%\n  filter(betweenness &gt;= 50) %&gt;%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10))+\n  geom_node_text(aes(label = id, filter= betweenness &gt;=50 & degree &gt;0), repel = TRUE)+\n  theme_graph()\n\n\n\n\n\n\n\nShow the code\nlist_top_30 &lt;- Noofowners %&gt;%\n  arrange(desc(count)) %&gt;%\n  top_n(30, wt = count) \n\nggplot(data = list_top_30, \n       aes(x = reorder(source, -count), y = count)) +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "Using the data provide by the VAST challenge, we are looking into the Mini-Challenge 2 (MC2) to identify compaines possibly engaged in illegal, unreported, and unregulated (IUU) fishing.\nWhen looking into IUU, we need to understand transshipment plays crucial roles in facilitating IUU fishing. Fishing ships will transfer its catch to other ships which would launder the catch to other countries - presumably their won. According to OCEANS, as many as 20% of global fishing catch is from IUU sources.\nIn the MC2 also mentioned that, when comapnies caught fishing illegally will shut down but will then often start up again under a different name, below we will visualize temporal patterns to identify if there are companies like this.\nBelow, we will use Social Network Analysis (SNA) and other relevant tools to understand to observe if we could uncover suspicious IUU activities."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#load-packages",
    "title": "Take Home Exercise 2",
    "section": "Load Packages",
    "text": "Load Packages\nThe code chunk below uses pacman::p_load() to check if packages are installed. If they are, they will be launched into R. The packages installed are\n\ntidyverse: A collection of core packages designed for data science, used extensively for data preparation and wrangling.\nggplot2: Used for plotting different types of graphs.\nggthemes: Provide additional themes for ggplot2 .\njsonlite: Used for loading json data file.\ntidygraph: Used for visualising network graph.\nvisNetwork: Used for visualising interactive network graph.\nggrepel: ggrepel provides geoms for ggplot2 to repel overlapping text labels.\nggraph: extension of ggplot2\nigraph: Network Analysis and Visualization.\n\n\n\nShow the code\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, tidyverse, lubridate, ggplot2, ggthemes, igraph, ggrepel)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-importing-and-wraggling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-importing-and-wraggling",
    "title": "Take Home Exercise 2",
    "section": "Data Importing and wraggling",
    "text": "Data Importing and wraggling\nImport the main MC2 data.\n\n\nShow the code\nMC2 &lt;- jsonlite::fromJSON(\"data/mc2_challenge_graph.json\")\n\nglimpse(MC2)\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 34576 obs. of  4 variables:\n  ..$ shpcountry: chr [1:34576] \"Polarinda\" NA \"Oceanus\" NA ...\n  ..$ rcvcountry: chr [1:34576] \"Oceanus\" NA \"Oceanus\" NA ...\n  ..$ dataset   : chr [1:34576] \"MC2\" \"MC2\" \"MC2\" \"MC2\" ...\n  ..$ id        : chr [1:34576] \"AquaDelight Inc and Son's\" \"BaringoAmerica Marine Ges.m.b.H.\" \"Yu gan  Sea spray GmbH Industrial\" \"FlounderLeska Marine BV\" ...\n $ links     :'data.frame': 5464378 obs. of  9 variables:\n  ..$ arrivaldate     : chr [1:5464378] \"2034-02-12\" \"2034-03-13\" \"2028-02-07\" \"2028-02-23\" ...\n  ..$ hscode          : chr [1:5464378] \"630630\" \"630630\" \"470710\" \"470710\" ...\n  ..$ valueofgoods_omu: num [1:5464378] 141015 141015 NA NA NA ...\n  ..$ volumeteu       : num [1:5464378] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ weightkg        : int [1:5464378] 4780 6125 10855 11250 11165 11290 9000 19490 6865 19065 ...\n  ..$ dataset         : chr [1:5464378] \"MC2\" \"MC2\" \"MC2\" \"MC2\" ...\n  ..$ source          : chr [1:5464378] \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" ...\n  ..$ target          : chr [1:5464378] \"BaringoAmerica Marine Ges.m.b.H.\" \"BaringoAmerica Marine Ges.m.b.H.\" \"-15045\" \"-15045\" ...\n  ..$ valueofgoodsusd : num [1:5464378] NA NA NA NA NA ...\n\n\nRun the below code chunk to preparing the node data. Upon looking into the node data, there are many missing data, to reduce the noise, we remove the missing data from here for further analysis.\n\n\nShow the code\nMC2_nodes &lt;- as_tibble(MC2$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\n\nglimpse(MC2_nodes)\n\n\nRows: 34,576\nColumns: 3\n$ id         &lt;chr&gt; \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry &lt;chr&gt; \"Polarinda\", NA, \"Oceanus\", NA, \"Oceanus\", \"Kondanovia\", NA…\n$ rcvcountry &lt;chr&gt; \"Oceanus\", NA, \"Oceanus\", NA, \"Oceanus\", \"Utoporiana\", NA, …\n\n\nShow the code\nany(is.na(MC2_nodes))\n\n\n[1] TRUE\n\n\nShow the code\nMC2_nodes_cleaned &lt;- na.omit(MC2_nodes)\n\nany(is.na(MC2_nodes_cleaned))\n\n\n[1] FALSE\n\n\nRun the below code chunk to prepare edge data. Month_Yr and Year were extracted for the temporal analysis in the later part.\n\n\nShow the code\nMC2_edges &lt;- as_tibble(MC2$links) %&gt;%\n  mutate(\n    Date = as.Date(arrivaldate),\n    Month_Yr = format(Date, \"%Y-%m\"),\n    Year = year(Date)) %&gt;%\n  select(source, target, Date, Month_Yr, Year, hscode) %&gt;% \n  distinct()\n\n\nHscode is the Harmonized System with standardized numerical method of classifying traded products. Since we are interested in the fish related products, hscode that is related to fish and its products are shown in the table below.\n\n\n\n\n\nCode chunk is run to filter all the hscode with fish related trades and identify the top 3 most traded fish products, namely,\n\n306170: Other shirmps and prawns\n304620: Catfish\n160414: Tunas, Skipjack And Bonito (sarda Spp), Prepared Or Preserved, Whole Or In Pieces, But Not Minced\n\n\n\nShow the code\ndistinct_hscode &lt;- unique(MC2_edges$hscode)\nfiltered_hscode &lt;- distinct_hscode[grepl(\"^30[1-8]|^160[4-5]|^2301|^1212|^1302|^1504|^151610|^151790\",distinct_hscode)]\n\nfiltered_MC2_edges &lt;- MC2_edges[MC2_edges$hscode %in% filtered_hscode, ]\n\ntop_3_hscode &lt;- filtered_MC2_edges %&gt;%\n  count(hscode) %&gt;%\n  arrange(desc(n)) %&gt;%\n  head(3) %&gt;%\n  pull(hscode)\n\ntop_3_hscode\n\n\n[1] \"306170\" \"304610\" \"160414\"\n\n\nCode chunk below run to filter the edges involve the top 3 appeared hscodes.\n\n\nShow the code\nMC2_edges_aggregated &lt;- filtered_MC2_edges %&gt;%\n  filter(hscode %in% c(\"306170\", \"304610\", \"160414\"))%&gt;%\n  group_by(source, target, hscode, Month_Yr, Year) %&gt;%\n    summarise(weights = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 10) %&gt;%\n  ungroup()\n\nglimpse(MC2_edges_aggregated)\n\n\nRows: 685\nColumns: 6\n$ source   &lt;chr&gt; \"Adair Salmon ОАО Family\", \"Adriatic Tuna AS Solutions\", \"Adr…\n$ target   &lt;chr&gt; \"hǎi dǎn Corporation Wharf\", \"Caracola del Sol Services\", \"Ca…\n$ hscode   &lt;chr&gt; \"160414\", \"306170\", \"306170\", \"306170\", \"306170\", \"306170\", \"…\n$ Month_Yr &lt;chr&gt; \"2033-11\", \"2032-08\", \"2032-10\", \"2029-07\", \"2029-08\", \"2029-…\n$ Year     &lt;dbl&gt; 2033, 2032, 2032, 2029, 2029, 2029, 2029, 2029, 2030, 2030, 2…\n$ weights  &lt;int&gt; 11, 11, 14, 12, 12, 15, 12, 15, 11, 13, 11, 14, 11, 11, 11, 1…\n\n\nRun the below codes to ensure our nodes data is cleaned and ready to be used for visualization below.\n\n\nShow the code\nid1 &lt;- MC2_edges_aggregated %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- MC2_edges_aggregated %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nMC2_nodes_extracted &lt;- rbind(id1, id2) %&gt;%\n  distinct()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-network-graph",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-network-graph",
    "title": "Take Home Exercise 2",
    "section": "Plot Network Graph",
    "text": "Plot Network Graph\n\n\nShow the code\nset.seed (1234)\nV(mc2_graph)$degree &lt;- degree(mc2_graph, mode = \"in\")\n\nggraph(mc2_graph, 'igraph', algorithm = 'fr') + \n  geom_edge_link0(aes(width = weights), edge_alpha = 0.1) + \n  geom_node_point(aes(size = degree, color = degree &gt; 20)) +\n  scale_color_manual(values = c(\"steelblue\", \"red\"), \n                     breaks = c(FALSE, TRUE), \n                     labels = c(\"Degree &lt;= 20\", \"Degree &gt; 20\")) +\n  geom_node_text(aes(label = id, filter = degree &gt; 20), color = 'black', \n                 size = 3, repel = TRUE) +\n  ggforce::theme_no_axes()\n\n\n\n\n\nWe are also interested to know the high out-degree nodes, and later in the interactive nodes, we can example if any of these high out-degree nodes actually supplies to the above high in-dgree nodes.\n\n\nShow the code\nset.seed (1234)\nV(mc2_graph)$degree &lt;- degree(mc2_graph, mode = \"out\")\n\nggraph(mc2_graph, 'igraph', algorithm = 'fr') + \n  geom_edge_link0(aes(width = weights), edge_alpha = 0.1) + \n  geom_node_point(aes(size = degree, color = degree &gt; 20)) +\n  scale_color_manual(values = c(\"steelblue\", \"red\"), \n                     breaks = c(FALSE, TRUE), \n                     labels = c(\"Degree &lt;= 20\", \"Degree &gt; 20\")) +\n  geom_node_text(aes(label = id, filter = degree &gt; 20), color = 'black', \n                 size = 3, repel = TRUE) +\n  ggforce::theme_no_axes()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-temporal-graph",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-temporal-graph",
    "title": "Take Home Exercise 2",
    "section": "Plot Temporal Graph",
    "text": "Plot Temporal Graph\nBased on the network graphs above, we realized that weights become significant when its more than 15, hence, below we plot the calendar heatmap for companies have higher activities (weight &gt;= 15) to understand their trading patterns over time.\n\n\nShow the code\nMC2_edges_aggregated$Month_Yr &lt;- as.Date(paste0(MC2_edges_aggregated$Month_Yr, \"-01\"), format = \"%Y-%m-%d\")\n\n\ntop_weights &lt;- MC2_edges_aggregated%&gt;%\n  filter(weights &gt;= 15)\n\n ggplot(top_weights, aes(x=Month_Yr, y=target, fill=weights))+\n  geom_tile(colour=\"White\", show.legend=FALSE)+\n  theme_classic()+\n  scale_fill_distiller(palette=\"Spectral\")\n\n\n\n\n\n\n\nShow the code\n ggplot(top_weights, aes(x=Month_Yr, y=source, fill=weights))+\n  geom_tile(colour=\"White\", show.legend=FALSE)+\n  theme_classic()+\n  scale_fill_distiller(palette=\"Spectral\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#insights",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#insights",
    "title": "Take Home Exercise 2",
    "section": "Insights",
    "text": "Insights\nBased on the network graphs and the heatmaps rom the above two network graph, some companies have high in/out degree but their activties are consistent across the time, hence we would think that those are the legal companies, and I have identified some prominent company pairs in the table below that caught my attention with their abrupt activities in the heatmap.\n\n\n\n\n\n\n\nHigh in-degree companies\nHigh out-degree companies\n\n\n\n\nYu xian SRL Industrial\nKerala Market - Ges.m.b.H. Cargo\n\n\nVolga River LLC Enterprises\nEstrella de la Costa SRL\n\n\nSea Breeze Corporation Marine sanctuary\nManipur Market Corporation Cargo\n\n\nSea Turtle GmbH & Co. KG\nDutch Eel AB Holdings\n\n\n\nThese companies form the demand-supply pairs, as seemed in the network graphs, and from the calendar heatmap, we can see their activtities match - both will be active in the same period and then disappear after “getting caught”. These could be suspicious companies that we should look into more details in the personels involved to see if there are any leads."
  }
]