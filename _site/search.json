[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hand-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman pacakge to check if tidyverse packages are installed in the comupter. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-bar-chart",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-bar-chart",
    "title": "Hand-on Exercise 1",
    "section": "Plotting a simple bar chart",
    "text": "Plotting a simple bar chart\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar()\n\n\n\n\n\nModifying a geometric object by changing geom()\n\nggplot(data=exam_data,\n       aes(x= MATHS)) +\n  geom_histogram(bins = 20,\n                 color=\"black\",\n                 fill= \"light blue\")\n\n\n\n\n\n\nModifying a geometric object by changing aes()\n\nggplot(data=exam_data,\n       aes(x= MATHS,\n           fill = GENDER)) +\n  geom_histogram(bins=20,\n                 color=\"grey30\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_density",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_density",
    "title": "Hand-on Exercise 1",
    "section": "Geometric Objects: geom_density()",
    "text": "Geometric Objects: geom_density()\nThis is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()        \n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "title": "Hand-on Exercise 1",
    "section": "Geometric Objects: geom_boxplot",
    "text": "Geometric Objects: geom_boxplot\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\nAdding in notches\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_violin",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_violin",
    "title": "Hand-on Exercise 1",
    "section": "Geometric Objects: geom_violin",
    "text": "Geometric Objects: geom_violin\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "title": "Hand-on Exercise 1",
    "section": "Geometric Objects: geom_point()",
    "text": "Geometric Objects: geom_point()\nThis is useful for creating scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geom-objects-can-be-combined",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geom-objects-can-be-combined",
    "title": "Hand-on Exercise 1",
    "section": "geom objects can be combined",
    "text": "geom objects can be combined\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "title": "Hand-on Exercise 1",
    "section": "Working with stat - the stat_summary() method",
    "text": "Working with stat - the stat_summary() method\nbelow code showing mean in red dots.\n\nggplot(data = exam_data,\n       aes(y = MATHS, x = GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4) \n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "title": "Hand-on Exercise 1",
    "section": "Working with stat - the geom() method",
    "text": "Working with stat - the geom() method\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)  \n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "title": "Hand-on Exercise 1",
    "section": "Adding a best fit curve on a scatterplot",
    "text": "Adding a best fit curve on a scatterplot\nusing geom_smooth(size=0.5)\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nThe default smoothing method (default is loess) can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "title": "Hand-on Exercise 1",
    "section": "Working with facet_wrap()",
    "text": "Working with facet_wrap()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "pacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "title": "Hands-on_Ex02",
    "section": "Working with ggrepel",
    "text": "Working with ggrepel\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: ggrepel: 317 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-Class Exercise 4",
    "section": "",
    "text": "Getting Started\n\npacman::p_load(rstatix, gt, patchwork, tidyverse)\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\n\nVisualising Normal Distribution\nIf the data is normally distributed, the points in a Q-Q plot will lie on a straight diagonal line. Conversely, if the points deviate significantly from the straight diagonal line, then it’s likes likely that the data is normally distributed.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam_data,\n       aes(sample=ENGLISH)) +\n  stat_qq() +\n  stat_qq_line()\n\n\n\n\n::: callout - Note Note: We can see that the points deviate significantly from the straight diagonal line. This is a clear indication that the set of data is not normally distributed. :::\n\n\nCombining satistical graph and analysis table\nNeed to install webshot\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nqq <- ggplot(exam_data,\n       aes(sample=ENGLISH)) +\n    stat_qq() +\n    stat_qq_line()\n\nsw_t <- exam_data %>%\n  shapiro_test(ENGLISH) %>%\n  gt()\n\n#converting the image into a temp file\ntmp <- tempfile(fileext = '.png')\ngtsave(sw_t,tmp)\ntable_png <- png::readPNG(tmp, native = TRUE)\n\nqq + table_png"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-Class Exercise 5",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-network-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-network-data",
    "title": "In-Class Exercise 5",
    "section": "Importing Network Data",
    "text": "Importing Network Data\n\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#review-the-imported-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#review-the-imported-data",
    "title": "In-Class Exercise 5",
    "section": "Review the imported data",
    "text": "Review the imported data\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#wrangling-time",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#wrangling-time",
    "title": "In-Class Exercise 5",
    "section": "Wrangling time",
    "text": "Wrangling time\n\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Application. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "City of Engagement, with a total population of 50,000, is a small city located at Country of Nowhere. The city serves as a service centre of an agriculture region surrounding the city. The main agriculture of the region is fruit farms and vineyards. The local council of the city is in the process of preparing the Local Plan 2023. A sample survey of 1000 representative residents had been conducted to collect data related to their household demographic and spending patterns, among other things. The city aims to use the data to assist with their major community revitalization efforts, including how to allocate a very large city renewal grant they have recently received.\nThe following analysis on the sample survey to reveal the demographic and financial characteristics of the city of Engagement byusing appropriate static and interactive statistical graphics methods. This analysis will be showing user-friendly and interactive solution that helps city managers and planners to explore the complex data in an engaging way and reveal hidden patterns."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-packages",
    "title": "Take Home Exercise 1",
    "section": "Load Packages",
    "text": "Load Packages\nThe code chunk below uses pacman::p_load() to check if packages are installed. If they are, they will be launched into R. The packages installed are\n\ntidyverse: A collection of core packages designed for data science, used extensively for data preparation and wrangling.\nggplot2: Used for plotting different types of graphs.\nplotly: Used for creating interactive web-based graphs.\nggdist: Used for visualising distribution and uncertainty.\nggridges: a ggplot2 extension specially designed for plotting ridgeline plots.\nggthemes: Provide additional themes for ggplot2 .\nggstatsplot: Used for creating graphics with details from statistical tests.\npacthwork: Used to combine plots.\nggrepel: ggrepel provides geoms for ggplot2 to repel overlapping text labels.\nAll packages can be found within CRAN.\n\n\n\nShow the code\npacman::p_load(tidyverse, ggplot2,plotly, ggdist, ggridges, ggthemes, colorspace, ggstatsplot, patchwork, ggrepel)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-importing-and-wraggling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-importing-and-wraggling",
    "title": "Take Home Exercise 1",
    "section": "Data importing and wraggling",
    "text": "Data importing and wraggling\nImport and check the columns in the Participant dataset.\n\n\nShow the code\nParticipants <- read_csv(\"data/participants.csv\") %>%\n  mutate_if(is.character, as.factor)\n\nglimpse(Participants)\n\n\nRows: 1,011\nColumns: 7\n$ participantId  <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ householdSize  <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ haveKids       <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T…\n$ age            <dbl> 36, 25, 35, 21, 43, 32, 26, 27, 20, 35, 48, 27, 34, 18,…\n$ educationLevel <fct> HighSchoolOrCollege, HighSchoolOrCollege, HighSchoolOrC…\n$ interestGroup  <fct> H, B, A, I, H, D, I, A, G, D, D, F, D, J, H, I, J, I, I…\n$ joviality      <dbl> 0.001626703, 0.328086500, 0.393469590, 0.138063446, 0.8…\n\n\nGroup the participants into 9 different Age Groups for easier analysis later.\n\n\nShow the code\nParticipants$age_group <- cut(Participants$age,\n                              breaks = c(-Inf,21, 26, 31, 36, 41, 46, 51, 56, Inf),\n                              labels = c(\"<20\", \"21-25\", \"26-30\",\"31-35\", \"36-40\", \n                                             \"41-45\", \"46-50\",\"51-55\", \"56-60\"),\n                              right = FALSE)\n\nParticipants$age <- NULL\n\n\nImport and read the FinancialJournal Dataset, extract out Category to the columns.\n\n\nShow the code\nFinancialJournal <- read_csv(\"data/FinancialJournal.csv\") %>%\n  mutate_if(is.character, as.factor)\n\nFin_by_cat <- FinancialJournal %>%\n  mutate(date = as.Date(timestamp)) %>%\n  group_by(participantId, category, timestamp) %>%\n  summarize(amount = sum(amount)) %>%\n  pivot_wider(names_from = category, values_from = amount)\n\n\nExtract the month_year out of timestamp.\n\n\nShow the code\nFin_split_ym <- Fin_by_cat %>%  \n    mutate(\n    Date = as.Date(timestamp),\n    Month_Yr = format(Date, \"%Y-%m\")) \n\n\nAs some participants have rent adjustment, new column is created, AdjustedShelter, to see the actual expense on shelter. Summarized the expenses by categories and group by Month_Yr, included two columns of Total Expense and Total Savings for later use.\n\n\nShow the code\nFin_summ <- Fin_split_ym %>% \n  group_by(participantId, Month_Yr) %>% \n  summarize(\n    Education = sum(Education, na.rm = TRUE),\n    Food = sum(Food, na.rm = TRUE),\n    Recreation = sum(Recreation, na.rm = TRUE),\n    Shelter = sum(Shelter, na.rm = TRUE),\n    Wage = sum(Wage, na.rm = TRUE),\n    RentAdjustment = sum(RentAdjustment, na.rm = TRUE),\n  ) %>% \n  ungroup()%>%\n  mutate(\n    AdjustedShelter = Shelter + RentAdjustment,\n    TotalExpense = Food + Recreation + AdjustedShelter + Education,\n    TotalSavings = Wage + TotalExpense)\n\nFin_summ$Education <- abs(Fin_summ$Education)\nFin_summ$Food <- abs(Fin_summ$Food)\nFin_summ$Recreation <- abs(Fin_summ$Recreation)\nFin_summ$AdjustedShelter <- abs(Fin_summ$AdjustedShelter)\nFin_summ$TotalExpense <- abs(Fin_summ$TotalExpense)\n\n\nJoin the two tables and remove the irrelevant columns for analysis and visualization later and check for any missing values.\n\n\nShow the code\nFin_byparticipant <- Fin_summ %>%\n  group_by(participantId) %>%\n  summarize(\n    Education = sum(Education, na.rm = TRUE),\n    Food = sum(Food, na.rm = TRUE),\n    Recreation = sum(Recreation, na.rm = TRUE),\n    Wage = sum(Wage, na.rm = TRUE),\n    AdjustedShelter = sum(AdjustedShelter, na.rm = TRUE),\n    TotalExpense = sum (TotalExpense, na.rm = TRUE),\n    TotalSavings = sum(TotalSavings, na.rm = TRUE)\n  ) \n\nMerged_table <- Fin_byparticipant %>%\n  inner_join(Participants, by = \"participantId\")\n\nany(is.na(Merged_table))\n\n\n[1] FALSE\n\n\nSummary of the statistics of the merged_table.\n\n\nShow the code\npsych::describe(Merged_table)\n\n\n                vars    n     mean       sd   median  trimmed      mad     min\nparticipantId      1 1011   505.00   291.99   505.00   505.00   375.10    0.00\nEducation          2 1011   152.69   316.73     0.00    68.07     0.00    0.00\nFood               3 1011  3663.13  1644.70  3586.59  3846.71   894.82   32.00\nRecreation         4 1011  4098.26  2602.62  4568.99  4114.17  2408.58    0.00\nWage               5 1011 45101.56 30567.82 40996.93 42117.39 22049.97 2098.36\nAdjustedShelter    6 1011  7173.23  3782.25  7845.02  7336.09  3554.77    0.00\nTotalExpense       7 1011 15087.30  7186.62 16693.90 15732.40  4991.29   32.00\nTotalSavings       8 1011 30014.26 28636.21 22757.71 25170.77 22164.44 1276.08\nhouseholdSize      9 1011     1.96     0.79     2.00     1.96     1.48    1.00\nhaveKids          10 1011      NaN       NA       NA      NaN       NA     Inf\neducationLevel*   11 1011     2.46     0.93     3.00     2.47     0.00    1.00\ninterestGroup*    12 1011     5.63     2.91     6.00     5.66     4.45    1.00\njoviality         13 1011     0.49     0.29     0.48     0.49     0.37    0.00\nage_group*        14 1011     5.19     2.48     5.00     5.21     2.97    1.00\n                      max     range  skew kurtosis     se\nparticipantId     1010.00   1010.00  0.00    -1.20   9.18\nEducation         1184.87   1184.87  2.23     3.89   9.96\nFood              6889.07   6857.07 -0.95     0.52  51.73\nRecreation       10285.19  10285.19 -0.30    -0.90  81.85\nWage            211734.65 209636.29  1.41     3.81 961.37\nAdjustedShelter  20232.63  20232.63 -0.30    -0.03 118.95\nTotalExpense     32554.69  32522.69 -0.85     0.08 226.02\nTotalSavings    195298.22 194022.14  1.95     5.19 900.62\nhouseholdSize        3.00      2.00  0.06    -1.41   0.02\nhaveKids             -Inf      -Inf    NA       NA     NA\neducationLevel*      4.00      3.00 -0.41    -0.96   0.03\ninterestGroup*      10.00      9.00 -0.07    -1.24   0.09\njoviality            1.00      1.00  0.08    -1.23   0.01\nage_group*           9.00      8.00 -0.05    -1.19   0.08\n\n\nThere are some high range in the TotalExpense, this is an important parameter to note, as the grant would likely to be used in the area where the citizens are spending at to make them happier. We plot the graph below to understand more on the overall spending pattern.\n\n\nShow the code\nggplot(data=Merged_table, \n       aes(x= TotalExpense, \n           y= joviality)) +\n  geom_point()    \n\n\n\n\n\nFrom the above graph, we can see that there are a group of sample have abnormally low spending and their happiness does not seem to matter on the amount they spend. These are the outliers in the sample that we should exclude from the analysis as it will affect the accuracy how we are determining the tangible spending that makes the citizens happy. Below code are performed to removed these outliers and check the graph again after the removal.\n\n\nShow the code\nTotalExpense_lower <- quantile(Merged_table$TotalExpense, 0.13)\n\nMerged_table_filtered <- Merged_table %>%\n  filter(TotalExpense >= TotalExpense_lower)\n\nggplot(data=Merged_table_filtered, \n       aes(x= TotalExpense, \n           y= joviality)) +\n  geom_point()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#normality-assumption-check",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#normality-assumption-check",
    "title": "Take Home Exercise 1",
    "section": "Normality Assumption Check",
    "text": "Normality Assumption Check\nTo check is joviality of the sample are normally distributed, we plotted the below bar chart and density graph to understand.\n\n\nShow the code\np1 <- ggplot(data=Merged_table_filtered, \n       aes(x= joviality)) +\n    geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")\n\np2 <- ggplot(data=Merged_table_filtered, \n       aes(x= joviality)) +\n    geom_density()\n\np1+p2\n\n\n\n\n\nWe can see from the above group that, joviality scores are not normally distributed in this sample."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#two-sample-test",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#two-sample-test",
    "title": "Take Home Exercise 1",
    "section": "Two-Sample Test",
    "text": "Two-Sample Test\nSince joviality is not normally distributed, we use ggbetweenstats() to understand if having kids have an impact on people’s happiness. Non-parametric test (Mann-Whitney U test) was carried out for the below hyphothesis.\n\nH0: There is no difference between average joviality score of people have kids.\nH1: There is difference between average joviality score of people have kids.\n\n\n\nShow the code\nggbetweenstats(\n  data = Merged_table_filtered,\n  x = haveKids, \n  y = joviality,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\nSince, p-value is greater than 0.05, we conclude that there is no difference between between average joviality score of people have kids."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#one-way-anova-test",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#one-way-anova-test",
    "title": "Take Home Exercise 1",
    "section": "One-Way Anova Test",
    "text": "One-Way Anova Test\nAs other categorical parameters have more than 2 groups, we use One-Way ANOVA test for the following hypothesis.\n\nH0: There is no difference among average joviality score of people of different educational levels.\nH1: There is difference among average joviality score of people of different educational levels.\n\n\n\nShow the code\nggbetweenstats(\n  data = Merged_table_filtered,\n  x = educationLevel, \n  y = joviality,\n  type = \"np\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\nSince, p-value is less than 0.05, we conclude that there is difference among average joviality score of people of different educational levels. We repeat the same test for the other parameters, i.e. household sizes, age groups, and conclude that these 3 parameters did not have significant statistical significance in affecting the citizen’s joviality score.\n\n\nShow the code\np3 <- ggbetweenstats(\n  data = Merged_table_filtered,\n  x = householdSize, \n  y = joviality,\n  type = \"np\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\np4 <- ggbetweenstats(\n  data = Merged_table_filtered,\n  x = age_group, \n  y = joviality,\n  type = \"np\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\np5 <- ggbetweenstats(\n  data = Merged_table_filtered,\n  x = interestGroup, \n  y = joviality,\n  type = \"np\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\np3|(p4/p5)\n\n\n\n\n\nWe would like to look into more on the joviality score is distributed among people of different education levels and we run the code chunk below.\n\n\nShow the code\nggplot(Merged_table_filtered, \n       aes(x = educationLevel, \n           y = joviality)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n    stat_summary(geom = \"point\",\n               fun=\"mean\",\n               colour =\"red\",\n               size=2) +\n  stat_summary(aes(label = round(after_stat(y), 2)), fun=mean, geom = \"label_repel\", size=3, angle=150)+\n  coord_flip() +\n  theme_economist()\n\n\n\n\n\nInsights:\n\nPeople of Low education level, has lower average joviality score than the rest, its median is also much lower and far from its average point due to a large number of them have low scores as shown by the higher ridge.\nGraduates have the highest joviality score, followed by Bachelors and High School or College graduates.\nCompared to the Graduates and Bachelors, there is also a large amount of High School or College graduates are of lower joviality score."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#correlation-matrix",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#correlation-matrix",
    "title": "Take Home Exercise 1",
    "section": "Correlation Matrix",
    "text": "Correlation Matrix\nNow we want to look at the continuous variables to understand how educational levels could play a part in affecting joviality score.\nFrom the Correlogram below, we have a few observations below,\n\nThere are a few pairs with high collinearity: TotalSavings-Wage, TotalExpense-AdjustedShelter, TotalExpense-Recreation. Hence, we will only consider Wage, AdjustedShelter and Recreation for the analysis below.\nJoviality Score has linear relationships with Wage received, Recreation, Food and Housing Expenses.\n\n\n\nShow the code\nggstatsplot::ggcorrmat(\n  data = Merged_table_filtered,\n  cor.vars = c(2:8,13),\n    ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for Merged_table2 dataset\",\n  subtitle = \"Three pairs are no significant at p < 0.05\"\n    )\n\n\n\n\n\n\n\nShow the code\np6 <- ggplot(data=Merged_table_filtered, \n       aes(y = Recreation, x= educationLevel)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",\n               fun=\"mean\",\n               colour =\"red\",\n               size=2) +\n  stat_summary(aes(label = round(after_stat(y), 2)), fun=mean, geom = \"label_repel\", size=3, angle=150) +\n  labs(y= 'Recreation Expense', x= 'Educational Level',\n       title = \"Distribution of Recreation Expense by Education Level\") +\n  theme(axis.title.y= element_text(angle=90), axis.ticks.x= element_blank(),\n        axis.line= element_line(color= 'grey'))\n\np7 <- ggplot(data=Merged_table_filtered, \n       aes(y = Food, x= educationLevel)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",\n               fun=\"mean\",\n               colour =\"red\",\n               size=2) +\n  stat_summary(aes(label = round(after_stat(y), 2)), fun=mean, geom = \"label_repel\", size=3, angle=150) +\n  labs(y= 'Food Expense', x= 'Educational Level',\n       title = \"Distribution of Food Expense by Education Level\") +\n  theme(axis.title.y= element_text(angle=90), axis.ticks.x= element_blank(),\n        axis.line= element_line(color= 'grey'))\n\np8 <- ggplot(data=Merged_table_filtered, \n       aes(y = AdjustedShelter, x= educationLevel)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",\n               fun=\"mean\",\n               colour =\"red\",\n               size=2) +\n  stat_summary(aes(label = round(after_stat(y), 2)), fun=mean, geom = \"label_repel\", size=3, angle=150) +\n  labs(y= 'Housing Expense', x= 'Educational Level',\n       title = \"Distribution of Housing Expense by Educational Level\") +\n  theme(axis.title.y= element_text(angle=90), axis.ticks.x= element_blank(),\n        axis.line= element_line(color= 'grey'))\n\np9 <- ggplot(data=Merged_table_filtered, \n       aes(y = Wage, x= educationLevel)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",\n               fun=\"mean\",\n               colour =\"red\",\n               size=2) +\n  stat_summary(aes(label = round(after_stat(y), 2)), fun=mean, geom = \"label_repel\", size=3, angle=150) +\n  labs(y= 'Wage Received', x= 'Educational Level',\n       title = \"Distribution of Wage by Educational Level\") +\n  theme(axis.title.y= element_text(angle=90), axis.ticks.x= element_blank(),\n        axis.line= element_line(color= 'grey'))\n\n(p6/p7)|(p8/p9)\n\n\n\n\n\nFrom the boxplots above, we can observe\n\nRecreational spending is about the same across all educational levels.\nHousing spending is lower for Low and High School or Colleague graduates. Bachelors and Graduates spend similarly.\nFood expense have a wide disparity across educational groups for their mean and median values. For people of low education level, the upper quartile is much lower than the remaining groups\nGraduates have much higher average and median higher wage than the rest of the groups, followed by Bachelors. Low and High School or Colleague graduates have much lower wages."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#interactive-visualization",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#interactive-visualization",
    "title": "Take Home Exercise 1",
    "section": "Interactive Visualization",
    "text": "Interactive Visualization\nBelow interactive graphs, we can explore how each spending and wage are correlated with joviality scores by educational levels.\n\n\nShow the code\nplot_ly(data = Merged_table_filtered, \n        x = ~joviality, \n        y = ~Recreation, \n        color = ~ educationLevel)\n\n\n\n\n\n\nThe above graph show that the higher the spending, the happier the person no matter the educational levels of the person.\n\n\nShow the code\nplot_ly(data = Merged_table_filtered, \n        x = ~joviality, \n        y = ~Food, \n        color = ~educationLevel)\n\n\n\n\n\n\nFor food spending, its interestingly showing stepped distribution, across all educational levels, people spend more than $4500 tend to feel happier than those below.\n\n\nShow the code\nplot_ly(data = Merged_table_filtered, \n        x = ~joviality, \n        y = ~AdjustedShelter, \n        color = ~educationLevel)\n\n\n\n\n\n\nFor housing spend, this is the least linearly correlated with happiness, we can see that joviality score is quite evenly spread across all educational groups. However, interesting observations saw for people spend above 12k on housing, their joviality score all above 0.65. Majority of those who can spend 12k or more on housing are Graduates and Bachelors. On this note, it is likely that these people who spend more on housing, makes them happy to make house to the way they want it to be.\n\n\nShow the code\nplot_ly(data = Merged_table_filtered, \n        x = ~joviality, \n        y = ~Wage, \n        color = ~educationLevel)\n\n\n\n\n\n\nFor wage, it is negatively correlated to joviality score (i.e. the more the person earn, the unhappy he gets). This trend is true across all educational levels. However, this is to note that only when wage hits 75k when we look at the total sample population, we start to see more significant amount of people become unhappy; when we filter to see only High School or Low educational level graduates, the wage that make them unhappy is about 50k. This could be interpreted that at different education level, there might be the higher amount of stress and time spent that comes with the higher wage within their educational level."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualizing-the-uncertainty-of-point-estimates",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualizing-the-uncertainty-of-point-estimates",
    "title": "Take Home Exercise 1",
    "section": "Visualizing the uncertainty of point estimates",
    "text": "Visualizing the uncertainty of point estimates\nWe would like to exam further into uncertainties of the point estimates by educational level. With median used as point of estimate, quantile interval is used instead of confidence level (CI) , 95% and 99% intervals are used as well as these are the commonly used CI for hypothesis testing such as the ones above. As shown in the graph below, we can see that true (unknown) estimate indeed lie within the interval.\n\n\nShow the code\nMerged_table_filtered %>%\n  ggplot(aes(x = educationLevel, \n             y = joviality)) +\n  stat_pointinterval(\n    aes(interval_color = stat(level)),\n    .width = c(0.95,0.99),\n    .point = median,\n    .interval = qi,\n    point_color = \"darkred\",\n    show.legend = FALSE) +\n  labs(\n    title = \"Visualising confidence intervals of median joviality score by Educational Levels\",\n    subtitle = \"Median Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#other-interesting-observations",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#other-interesting-observations",
    "title": "Take Home Exercise 1",
    "section": "Other Interesting Observations",
    "text": "Other Interesting Observations\nAs we know that recreation could make people happier, it could be helpful to look into which interest groups get people make people happier.\n\n\nShow the code\nggplot(data=Merged_table_filtered, \n       aes(y = joviality, x= interestGroup)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",\n               fun=\"median\",\n               colour =\"red\",\n               size=2) +\n  stat_summary(aes(label = round(after_stat(y), 2)), fun=mean, geom = \"label_repel\", size=3, angle=150) +\n  labs(y= 'Joviality', x= 'Interest Groups',\n       title = \"Distribution of Joviality across Age Groups by Interest Groups\") +\n  theme(axis.title.y= element_text(angle=90), axis.ticks.x= element_blank(),\n        axis.line= element_line(color= 'grey'))\n\n\n\n\n\nThe above boxplot show that Group E has the highest score. Separate the overall distribution to two groups of people have kids or not have kids, we can see for group B, C, D and H, people with kids are much unhappier, while for group G and I, people with kids are much happier.\n\n\nShow the code\nggplot(data=Merged_table_filtered, \n       aes(y = joviality, x= interestGroup)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",\n               fun=\"median\",\n               colour =\"red\",\n               size=2) +\n  stat_summary(aes(label = round(after_stat(y), 2)), fun=mean, geom = \"label_repel\", size=3, angle=150) +\n  facet_grid(haveKids ~.) +\n  labs(y= 'Joviality', x= 'Interest Groups',\n       title = \"Distribution of Joviality across Age Groups by Interest Groups\")  +\n  theme(axis.title.y= element_text(angle=90), axis.ticks.x= element_blank(),\n        axis.line= element_line(color= 'grey'))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "Using the data provide by the VAST challenge, we are looking into the Mini-Challenge 2 (MC2) to identify compaines possibly engaged in illegal, unreported, and unregulated (IUU) fishing.\nWhen looking into IUU, we need to understand transshipment plays crucial roles in facilitating IUU fishing. Fishing ships will transfer its catch to other ships which would launder the catch to other countries - presumably their won. According to OCEANS, as many as 20% of global fishing catch is from IUU sources.\nIn the MC2 also mentioned that, when comapnies caught fishing illegally will shut down but will then often start up again under a different name, below we will visualize temporal patterns to identify if there are companies like this.\nBelow, we will use Social Network Analysis (SNA) and other relevant tools to understand to observe if we could uncover suspicious IUU activities."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#load-packages",
    "title": "Take Home Exercise 2",
    "section": "Load Packages",
    "text": "Load Packages\nThe code chunk below uses pacman::p_load() to check if packages are installed. If they are, they will be launched into R. The packages installed are\n\ntidyverse: A collection of core packages designed for data science, used extensively for data preparation and wrangling.\nggplot2: Used for plotting different types of graphs.\nggthemes: Provide additional themes for ggplot2 .\njsonlite: Used for loading json data file.\ntidygraph: Used for visualising network graph.\nvisNetwork: Used for visualising interactive network graph.\nggrepel: ggrepel provides geoms for ggplot2 to repel overlapping text labels.\nggraph: extension of ggplot2\nigraph: Network Analysis and Visualization.\n\n\n\nShow the code\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, tidyverse, lubridate, ggplot2, ggthemes, igraph, ggrepel)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-importing-and-wraggling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-importing-and-wraggling",
    "title": "Take Home Exercise 2",
    "section": "Data Importing and wraggling",
    "text": "Data Importing and wraggling\nImport the main MC2 data.\n\n\nShow the code\nMC2 <- jsonlite::fromJSON(\"data/mc2_challenge_graph.json\")\n\nglimpse(MC2)\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 34576 obs. of  4 variables:\n  ..$ shpcountry: chr [1:34576] \"Polarinda\" NA \"Oceanus\" NA ...\n  ..$ rcvcountry: chr [1:34576] \"Oceanus\" NA \"Oceanus\" NA ...\n  ..$ dataset   : chr [1:34576] \"MC2\" \"MC2\" \"MC2\" \"MC2\" ...\n  ..$ id        : chr [1:34576] \"AquaDelight Inc and Son's\" \"BaringoAmerica Marine Ges.m.b.H.\" \"Yu gan  Sea spray GmbH Industrial\" \"FlounderLeska Marine BV\" ...\n $ links     :'data.frame': 5464378 obs. of  9 variables:\n  ..$ arrivaldate     : chr [1:5464378] \"2034-02-12\" \"2034-03-13\" \"2028-02-07\" \"2028-02-23\" ...\n  ..$ hscode          : chr [1:5464378] \"630630\" \"630630\" \"470710\" \"470710\" ...\n  ..$ valueofgoods_omu: num [1:5464378] 141015 141015 NA NA NA ...\n  ..$ volumeteu       : num [1:5464378] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ weightkg        : int [1:5464378] 4780 6125 10855 11250 11165 11290 9000 19490 6865 19065 ...\n  ..$ dataset         : chr [1:5464378] \"MC2\" \"MC2\" \"MC2\" \"MC2\" ...\n  ..$ source          : chr [1:5464378] \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" ...\n  ..$ target          : chr [1:5464378] \"BaringoAmerica Marine Ges.m.b.H.\" \"BaringoAmerica Marine Ges.m.b.H.\" \"-15045\" \"-15045\" ...\n  ..$ valueofgoodsusd : num [1:5464378] NA NA NA NA NA ...\n\n\nRun the below code chunk to preparing the node data. Upon looking into the node data, there are many missing data, to reduce the noise, we remove the missing data from here for further analysis.\n\n\nShow the code\nMC2_nodes <- as_tibble(MC2$nodes) %>%\n  select(id,shpcountry,rcvcountry)\n\nglimpse(MC2_nodes)\n\n\nRows: 34,576\nColumns: 3\n$ id         <chr> \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry <chr> \"Polarinda\", NA, \"Oceanus\", NA, \"Oceanus\", \"Kondanovia\", NA…\n$ rcvcountry <chr> \"Oceanus\", NA, \"Oceanus\", NA, \"Oceanus\", \"Utoporiana\", NA, …\n\n\nShow the code\nany(is.na(MC2_nodes))\n\n\n[1] TRUE\n\n\nShow the code\nMC2_nodes_cleaned <- na.omit(MC2_nodes)\n\nany(is.na(MC2_nodes_cleaned))\n\n\n[1] FALSE\n\n\nRun the below code chunk to prepare edge data. Month_Yr and Year were extracted for the temporal analysis in the later part.\n\n\nShow the code\nMC2_edges <- as_tibble(MC2$links) %>%\n  mutate(\n    Date = as.Date(arrivaldate),\n    Month_Yr = format(Date, \"%Y-%m\"),\n    Year = year(Date)) %>%\n  select(source, target, Date, Month_Yr, Year, hscode) %>% \n  distinct()\n\n\nHscode is the Harmonized System with standardized numerical method of classifying traded products. Since we are interested in the fish related products, hscode that is related to fish and its products are shown in the table below.\n\n\n\n\n\nCode chunk is run to filter all the hscode with fish related trades and identify the top 3 most traded fish products, namely,\n\n306170: Other shirmps and prawns\n304620: Catfish\n160414: Tunas, Skipjack And Bonito (sarda Spp), Prepared Or Preserved, Whole Or In Pieces, But Not Minced\n\n\n\nShow the code\ndistinct_hscode <- unique(MC2_edges$hscode)\nfiltered_hscode <- distinct_hscode[grepl(\"^30[1-8]|^160[4-5]|^2301|^1212|^1302|^1504|^151610|^151790\",distinct_hscode)]\n\nfiltered_MC2_edges <- MC2_edges[MC2_edges$hscode %in% filtered_hscode, ]\n\ntop_3_hscode <- filtered_MC2_edges %>%\n  count(hscode) %>%\n  arrange(desc(n)) %>%\n  head(3) %>%\n  pull(hscode)\n\ntop_3_hscode\n\n\n[1] \"306170\" \"304610\" \"160414\"\n\n\nCode chunk below run to filter the edges involve the top 3 appeared hscodes.\n\n\nShow the code\nMC2_edges_aggregated <- filtered_MC2_edges %>%\n  filter(hscode %in% c(\"306170\", \"304610\", \"160414\"))%>%\n  group_by(source, target, hscode, Month_Yr, Year) %>%\n    summarise(weights = n()) %>%\n  filter(source!=target) %>%\n  filter(weights > 10) %>%\n  ungroup()\n\nglimpse(MC2_edges_aggregated)\n\n\nRows: 685\nColumns: 6\n$ source   <chr> \"Adair Salmon ОАО Family\", \"Adriatic Tuna AS Solutions\", \"Adr…\n$ target   <chr> \"hǎi dǎn Corporation Wharf\", \"Caracola del Sol Services\", \"Ca…\n$ hscode   <chr> \"160414\", \"306170\", \"306170\", \"306170\", \"306170\", \"306170\", \"…\n$ Month_Yr <chr> \"2033-11\", \"2032-08\", \"2032-10\", \"2029-07\", \"2029-08\", \"2029-…\n$ Year     <dbl> 2033, 2032, 2032, 2029, 2029, 2029, 2029, 2029, 2030, 2030, 2…\n$ weights  <int> 11, 11, 14, 12, 12, 15, 12, 15, 11, 13, 11, 14, 11, 11, 11, 1…\n\n\nRun the below codes to ensure our nodes data is cleaned and ready to be used for visualization below.\n\n\nShow the code\nid1 <- MC2_edges_aggregated %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- MC2_edges_aggregated %>%\n  select(target) %>%\n  rename(id = target)\nMC2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-Class Exercise 7",
    "section": "",
    "text": "pacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\n\naverp <- read_csv(\"data/AVERP.csv\") %>%\n  mutate('Date' = dmy('Date'))\n\n\naverp %>% \n  filter(Date>= \"2018-01-01\") %>%\n  ggplot(data = ) +\n  geom_horizon(aes(x = Date, y= Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(\"Consumer Items\" ~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.x = element_text(size=7)\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take Home Exercise 3",
    "section": "",
    "text": "pacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, graphlayouts, ggforce, tidytext, tidyverse)\n\n\nmc3_data <- fromJSON(\"data/MC3.json\")\n\nExamine the data, this is not a directed graph, not looking into in- and out-degree of the nodes.\nBelow code chunk changes the links field into character field.\n\nmc3_edges <- as_tibble(mc3_data$links)%>%\n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %>%\n  group_by(source, target, type) %>%\n    summarise(weights = n()) %>%\n  filter(source!=target)%>%\n  ungroup\n\n`summarise()` has grouped output by 'source', 'target'. You can override using\nthe `.groups` argument.\n\n\n\nmc3_nodes <- as_tibble(mc3_data$nodes) %>%\n#  distinct()%>%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %>%\n    select(id, country, type, revenue_omu, product_services)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `revenue_omu = as.numeric(as.character(revenue_omu))`.\nCaused by warning:\n! NAs introduced by coercion\n\n\nConvert character(0) for type to NA for text sensing\n\nggplot(data = mc3_nodes,\n       aes(x=type)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-network-graph",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-network-graph",
    "title": "Take Home Exercise 2",
    "section": "Plot Network Graph",
    "text": "Plot Network Graph\n\n\nShow the code\nset.seed (1234)\nV(mc2_graph)$degree <- degree(mc2_graph, mode = \"in\")\n\nggraph(mc2_graph, 'igraph', algorithm = 'fr') + \n  geom_edge_link0(aes(width = weights), edge_alpha = 0.1) + \n  geom_node_point(aes(size = degree, color = degree > 20)) +\n  scale_color_manual(values = c(\"steelblue\", \"red\"), \n                     breaks = c(FALSE, TRUE), \n                     labels = c(\"Degree <= 20\", \"Degree > 20\")) +\n  geom_node_text(aes(label = id, filter = degree > 20), color = 'black', \n                 size = 3, repel = TRUE) +\n  ggforce::theme_no_axes()\n\n\n\n\n\nWe are also interested to know the high out-degree nodes, and later in the interactive nodes, we can example if any of these high out-degree nodes actually supplies to the above high in-dgree nodes.\n\n\nShow the code\nset.seed (1234)\nV(mc2_graph)$degree <- degree(mc2_graph, mode = \"out\")\n\nggraph(mc2_graph, 'igraph', algorithm = 'fr') + \n  geom_edge_link0(aes(width = weights), edge_alpha = 0.1) + \n  geom_node_point(aes(size = degree, color = degree > 20)) +\n  scale_color_manual(values = c(\"steelblue\", \"red\"), \n                     breaks = c(FALSE, TRUE), \n                     labels = c(\"Degree <= 20\", \"Degree > 20\")) +\n  geom_node_text(aes(label = id, filter = degree > 20), color = 'black', \n                 size = 3, repel = TRUE) +\n  ggforce::theme_no_axes()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-temporal-graph",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-temporal-graph",
    "title": "Take Home Exercise 2",
    "section": "Plot Temporal Graph",
    "text": "Plot Temporal Graph\nBased on the network graphs above, we realized that weights become significant when its more than 15, hence, below we plot the calendar heatmap for companies have higher activities (weight >= 15) to understand their trading patterns over time.\n\n\nShow the code\nMC2_edges_aggregated$Month_Yr <- as.Date(paste0(MC2_edges_aggregated$Month_Yr, \"-01\"), format = \"%Y-%m-%d\")\n\n\ntop_weights <- MC2_edges_aggregated%>%\n  filter(weights >= 15)\n\n ggplot(top_weights, aes(x=Month_Yr, y=target, fill=weights))+\n  geom_tile(colour=\"White\", show.legend=FALSE)+\n  theme_classic()+\n  scale_fill_distiller(palette=\"Spectral\")\n\n\n\n\n\n\n\nShow the code\n ggplot(top_weights, aes(x=Month_Yr, y=source, fill=weights))+\n  geom_tile(colour=\"White\", show.legend=FALSE)+\n  theme_classic()+\n  scale_fill_distiller(palette=\"Spectral\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#insights",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#insights",
    "title": "Take Home Exercise 2",
    "section": "Insights",
    "text": "Insights\nBased on the network graphs and the heatmaps rom the above two network graph, some companies have high in/out degree but their activties are consistent across the time, hence we would think that those are the legal companies, and I have identified some prominent company pairs in the table below that caught my attention with their abrupt activities in the heatmap.\n\n\n\n\n\n\n\nHigh in-degree companies\nHigh out-degree companies\n\n\n\n\nYu xian SRL Industrial\nKerala Market - Ges.m.b.H. Cargo\n\n\nVolga River LLC Enterprises\nEstrella de la Costa SRL\n\n\nSea Breeze Corporation Marine sanctuary\nManipur Market Corporation Cargo\n\n\nSea Turtle GmbH & Co. KG\nDutch Eel AB Holdings\n\n\n\nThese companies form the demand-supply pairs, as seemed in the network graphs, and from the calendar heatmap, we can see their activtities match - both will be active in the same period and then disappear after “getting caught”. These could be suspicious companies that we should look into more details in the personels involved to see if there are any leads."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#load-packages",
    "title": "Take Home Exercise 3",
    "section": "Load Packages",
    "text": "Load Packages\n\n\nShow the code\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, graphlayouts, ggforce,skimr,tidytext, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-import",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-import",
    "title": "Take Home Exercise 3",
    "section": "Data Import",
    "text": "Data Import\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC3.json into R environment.\n\n\nShow the code\nmc3_data <- fromJSON(\"data/MC3.json\")\n\n\nExamine the data, this is not a directed graph, not looking into in- and out-degree of the nodes."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-edges",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-edges",
    "title": "Take Home Exercise 3",
    "section": "Extracting edges",
    "text": "Extracting edges\nBelow code chunk changes the links field into character field.\n\n\nShow the code\nmc3_edges <- as_tibble(mc3_data$links)%>%\n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %>%\n  group_by(source, target, type) %>%\n    summarise(weights = n()) %>%\n  filter(source!=target)%>%\n  ungroup"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-nodes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extracting-nodes",
    "title": "Take Home Exercise 3",
    "section": "Extracting nodes",
    "text": "Extracting nodes\n\n\nShow the code\nmc3_nodes <- as_tibble(mc3_data$nodes) %>%\n#  distinct()%>%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %>%\n    select(id, country, type, revenue_omu, product_services)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploring-the-edges-data-frame",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploring-the-edges-data-frame",
    "title": "Take Home Exercise 3",
    "section": "Exploring the edges data frame",
    "text": "Exploring the edges data frame\nIn the code chunk below, skim() of skimr package is used to display the summary statistics of mc3_edges tibble data frame.\n\n\nShow the code\nskim(mc3_edges)\n\n\n\nData summary\n\n\nName\nmc3_edges\n\n\nNumber of rows\n24036\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsource\n0\n1\n6\n700\n0\n12856\n0\n\n\ntarget\n0\n1\n6\n28\n0\n21265\n0\n\n\ntype\n0\n1\n16\n16\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nweights\n0\n1\n1\n0\n1\n1\n1\n1\n1\n▁▁▇▁▁\n\n\n\n\n\nThe report above reveals that there is not missing values in all fields.\nIn the code chunk below, datatable() of DT package is used to display mc3_edges tibble data frame as an interactive table on the html document.\n\n\nShow the code\nDT::datatable(mc3_edges)\n\n\n\n\n\n\n\nConvert character(0) for type to NA for text sensing\n\n\nShow the code\nggplot(data = mc3_edges,\n       aes(x=type)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#building-network-model-with-tidygraph",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#building-network-model-with-tidygraph",
    "title": "Take Home Exercise 3",
    "section": "Building network model with tidygraph",
    "text": "Building network model with tidygraph\n\n\nShow the code\nid1 <- mc3_edges %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- mc3_edges %>%\n  select(target) %>%\n  rename(id = target)\nmc3_nodes1 <- rbind(id1, id2) %>%\n  distinct() %>%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n\n\n\n\nShow the code\nmc3_graph <- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\n\n\n\nShow the code\nmc3_graph %>%\n  filter(betweenness_centrality >= 100000) %>%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10))+\n  theme_graph()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploring-the-nodes-dataframe",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploring-the-nodes-dataframe",
    "title": "Take Home Exercise 3",
    "section": "Exploring the nodes dataframe",
    "text": "Exploring the nodes dataframe\n\n\nShow the code\nskim(mc3_nodes)\n\n\n\nData summary\n\n\nName\nmc3_nodes\n\n\nNumber of rows\n27622\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nid\n0\n1\n6\n64\n0\n22929\n0\n\n\ncountry\n0\n1\n2\n15\n0\n100\n0\n\n\ntype\n0\n1\n7\n16\n0\n3\n0\n\n\nproduct_services\n0\n1\n4\n1737\n0\n3244\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrevenue_omu\n21515\n0.22\n1822155\n18184433\n3652.23\n7676.36\n16210.68\n48327.66\n310612303\n▇▁▁▁▁\n\n\n\n\n\nThe report above reveals that there is no missing values in all fields.\nIn the code chunk below, datatable() of DT package is used to display mc3_nodes tibble data frame as an interactive table on the html document.\n\n\nShow the code\nDT::datatable(mc3_nodes)\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = mc3_nodes,\n       aes(x = type)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#simple-word-count",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#simple-word-count",
    "title": "Take Home Exercise 3",
    "section": "Simple word count",
    "text": "Simple word count\nThe code chunk below calculates number of times the word fish appeared in the field product_services.\n\n\nShow the code\nmc3_nodes %>% \n    mutate(n_fish = str_count(product_services, \"fish\")) \n\n\n# A tibble: 27,622 × 6\n   id                          country type  revenue_omu product_services n_fish\n   <chr>                       <chr>   <chr>       <dbl> <chr>             <int>\n 1 Jones LLC                   ZH      Comp…  310612303. Automobiles           0\n 2 Coleman, Hall and Lopez     ZH      Comp…  162734684. Passenger cars,…      0\n 3 Aqua Advancements Sashimi … Oceanus Comp…  115004667. Holding firm wh…      0\n 4 Makumba Ltd. Liability Co   Utopor… Comp…   90986413. Car service, ca…      0\n 5 Taylor, Taylor and Farrell  ZH      Comp…   81466667. Fully electric …      0\n 6 Harmon, Edwards and Bates   ZH      Comp…   75070435. Discount superm…      0\n 7 Punjab s Marine conservati… Riodel… Comp…   72167572. Beef, pork, chi…      0\n 8 Assam   Limited Liability … Utopor… Comp…   72162317. Power and Gas s…      0\n 9 Ianira Starfish Sagl Import Rio Is… Comp…   68832979. Light commercia…      0\n10 Moran, Lewis and Jimenez    ZH      Comp…   65592906. Automobiles, tr…      0\n# ℹ 27,612 more rows"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#tokenisation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#tokenisation",
    "title": "Take Home Exercise 3",
    "section": "Tokenisation",
    "text": "Tokenisation\nThe word tokenisation have different meaning in different scientific domains. In text sensing, tokenisation is the process of breaking up a given text into units called tokens. Tokens can be individual words, phrases or even whole sentences. In the process of tokenisation, some characters like punctuation marks may be discarded. The tokens usually become the input for the processes like parsing and text mining.\nIn the code chunk below, unnest_token() of tidytext is used to split text in product_services field into words.\n\n\nShow the code\ntoken_nodes <- mc3_nodes %>%\n  unnest_tokens(word, \n                product_services)\n\n\nThe two basic arguments to unnest_tokens() used here are column names. First we have the output column name that will be created as the text is unnested into it (word, in this case), and then the input column that the text comes from (product_services, in this case).\n\n\nShow the code\ntoken_nodes %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")\n\n\n\n\n\nThe bar chart reveals that the unique words contains some words that may not be useful to use. For instance \"a\" and \"to\". In the word of text mining we call those words stop words. You want to remove these words from your analysis as they are fillers used to compose a sentence."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#removing-stopwords",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#removing-stopwords",
    "title": "Take Home Exercise 3",
    "section": "Removing stopwords",
    "text": "Removing stopwords\n\n\nShow the code\nstopwords_removed <- token_nodes %>% \n  anti_join(stop_words)\n\n\n\n\nShow the code\nstopwords_removed %>%\n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n      labs(x = \"Count\",\n      y = \"Unique words\",\n      title = \"Count of unique words found in product_services field\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex08/data/geospatial/MPSZ-2019.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  }
]