---
title: "Take Home Exercise 3"
subtitle: "Uncover illegal, unreported, and unregulated (IUU) fishing activities through visual analytics"
format: 
  html: 
    code-fold: true
    code-summary: "Show the code"
author: "Fangxian"
execute: 
  eval: true
  warning: false
date: "4 June 2023"
date-modified: "`r Sys.Date()`"
---

# Task

# Data Wraggling

## Load Packages

```{r}
pacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, graphlayouts, ggforce,skimr,tidytext, tidyverse,igraph)
```

## Data Import

In the code chunk below, `fromJSON()` of **jsonlite** package is used to import *MC3.json* into R environment.

```{r}
mc3_data <- fromJSON("data/MC3.json")
```

Examine the data, this is not a directed graph, not looking into in- and out-degree of the nodes.

## Extracting edges

Below code chunk changes the links field into character field.

```{r}
mc3_edges <- as_tibble(mc3_data$links)%>%
  distinct() %>%
  mutate(source = as.character(source),
         target = as.character(target),
         type = as.character(type)) %>%
  group_by(source, target, type) %>%
    summarise(weights = n()) %>%
  filter(source!=target)%>%
  ungroup
```

## Extracting nodes

```{r}
mc3_nodes <- as_tibble(mc3_data$nodes) %>%
#  distinct()%>%
  mutate(country = as.character(country),
         id = as.character(id),
         product_services = as.character(product_services),
         revenue_omu = as.numeric(as.character(revenue_omu)),
         type = as.character(type)) %>%
    select(id, country, type, revenue_omu, product_services)
```

# Initial Data Exploration

## Exploring the edges dataframe

In the code chunk below, [`skim()`](https://docs.ropensci.org/skimr/reference/skim.html) of [**skimr**](https://docs.ropensci.org/skimr/) package is used to display the summary statistics of *mc3_edges* tibble data frame.

```{r}
skim(mc3_edges)
```

The report above reveals that there is not missing values in all fields.

In the code chunk below, `datatable()` of DT package is used to display mc3_edges tibble data frame as an interactive table on the html document.

```{r}
DT::datatable(mc3_edges)
```

counting number of companies a person owns

```{r}
ggplot(data = mc3_edges,
       aes(x=type)) +
  geom_bar()

unique_ids <- unique(mc3_edges$target)
num_unique_ids <- length(unique_ids)
num_unique_ids

Noofcompanies <- mc3_edges %>%
  group_by(target, source, type) %>%
  filter(type == "Beneficial Owner") %>%
  summarise(count=n()) %>%
  group_by(target)%>%
  summarise(count=sum(count))

psych::describe(Noofcompanies)

# list <- mc3_edges1 %>%
#   filter(mc3_edges1$count > 1)
# 
# psych::describe(list)
```

```{r}
Noofowners <- mc3_edges %>%
  group_by(source, target, type) %>%
  summarise(count=n()) %>%
  group_by(source)%>%
  summarise(count=sum(count))

psych::describe(Noofowners)
```

\

```{r}
list_top_50 <- Noofcompanies %>%
  arrange(desc(count)) %>%
  top_n(50, wt = count) 

ggplot(data = list_top_50, 
       aes(x = reorder(target, -count), y = count)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 
```

## Exploring the nodes dataframe

```{r}
skim(mc3_nodes)
```

The report above reveals that there is no missing values in all fields.

In the code chunk below, `datatable()` of DT package is used to display mc3_nodes tibble data frame as an interactive table on the html document.

```{r}
DT::datatable(mc3_nodes)
```

```{r}
ggplot(data = mc3_nodes,
       aes(x = type)) +
  geom_bar()
```

Check on the revenue

```{r}
ggplot(data = mc3_nodes,
       aes(x= type,
         y = revenue_omu)) +
  geom_boxplot()
```

```{r}
combined <- left_join(mc3_nodes,mc3_edges,
                  by=c("id"="source"))
```

Pivot to find out on the revenue fron the target. find out about which target has high revenue

```{r}
combined <- combined %>%
  group_by(target, type.y, id, country, type.x, product_services)%>%
  summarize(revenue_omu) %>%
  filter(type.y == "Beneficial Owner")

filtered_combined <- combined %>%
  filter(target %in% list_top_50$target)%>%
  arrange(desc(revenue_omu))

ggplot(data = filtered_combined, 
       aes(x = target, y = revenue_omu)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 
```

```{r}
Top_3_Revenue<- combined %>%
  filter (target %in% c("Michael Johnson", "Mark Miller","James Rodriguez")) %>%
  arrange(desc(revenue_omu))

DT::datatable(Top_3_Revenue)
```

# Text Sensing with tidytext

## Simple word count

The code chunk below calculates number of times the word *fish* appeared in the field *product_services*.

```{r}
mc3_nodes %>% 
    mutate(n_fish = str_count(product_services, "fish")) 
```

## Tokenisation

The word tokenisation have different meaning in different scientific domains. In text sensing, **tokenisation** is the process of breaking up a given text into units called **tokens**. Tokens can be individual words, phrases or even whole sentences. In the process of tokenisation, some characters like punctuation marks may be discarded. The tokens usually become the input for the processes like parsing and text mining.

In the code chunk below, [`unnest_token()`](https://juliasilge.github.io/tidytext/reference/unnest_tokens.html) of tidytext is used to split text in *product_services* field into words.

```{r}
token_nodes <- mc3_nodes %>%
  unnest_tokens(word, 
                product_services)
```

The two basic arguments to `unnest_tokens()` used here are column names. First we have the output column name that will be created as the text is unnested into it (*word*, in this case), and then the input column that the text comes from (*product_services*, in this case).

```{r}
token_nodes %>%
  count(word, sort = TRUE) %>%
  top_n(15) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
      labs(x = "Count",
      y = "Unique words",
      title = "Count of unique words found in product_services field")
```

The bar chart reveals that the unique words contains some words that may not be useful to use. For instance "a" and "to". In the word of text mining we call those words **stop words**. You want to remove these words from your analysis as they are fillers used to compose a sentence.

Using filter we also discover many "character(0)" which has no meaning in itself, we will also proceed to replace them with "NA".

## Removing stopwords

```{r}
token_nodes$word[token_nodes$word == "character"] <- "NA"
token_nodes$word[token_nodes$word == "0"] <- "NA"
```

```{r}
stopwords_removed <- token_nodes %>% 
  anti_join(stop_words)
```

```{r}
stopwords_removed %>%
  count(word, sort = TRUE) %>%
  top_n(15) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
      labs(x = "Count",
      y = "Unique words",
      title = "Count of unique words found in product_services field")
```

```{r}
stopwords_removed %>%
  count(word, sort = TRUE) %>%
  top_n(20) %>%
  mutate(word = reorder(word, n)) %>%
  filter(!word %in% head(word, 3)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
  labs(x = "Count",
       y = "Unique words",
       title = "Count of unique words found in product_services field")

```

# Initial Network Visualization and Analysis

## Building network model with tidygraph

```{r}
mc3_nodes_fish <- stopwords_removed %>%
  filter(stopwords_removed$word == "fish")
```

```{r}
mc3_edges_fish <- mc3_edges[mc3_edges$source %in% mc3_nodes_fish$id,]  
id1 <- mc3_edges_fish %>%
  select(source) %>%
  rename(id = source) 
id2 <- mc3_edges_fish %>% 
  select(target) %>% 
  rename(id = target) 
mc3_nodes_fish <- rbind(id1, id2) %>%
  distinct() %>% 
  left_join(mc3_nodes_fish,
            unmatched = "drop") 
```

```{r}
# mc3_graph <- tbl_graph(nodes = mc3_nodes_fish,                        
#                        edges = mc3_edges_fish,                        
#                        directed = FALSE)  mc3_graph
```

# Topic Modelling
